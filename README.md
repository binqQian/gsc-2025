# vcfComp
Extension of gsc compression tool.


```
./build/gsc -i input.txt -o compressed_output.br
./build/gsc -i compressed_output.br -o decompressed_output.txt -d

```

## Todo List
- [x] 改仓库名、更新文件名
### phase 1: I/O 处理 与 错误处理与验证、用户界面改进（小规模数据测试后再在大规模数据上测试）
- [ ] vcf.gz/gvcf.gz 解压到 vcf/gvcf 的同时，并行解析每行变体，分开存储每个字段的数据，从而变为一个待压缩的中间态
- [ ] 简单通过brotli压缩中间态生成gsc后缀格式的文件，然后将gsc格式文件解压并还原成vcf/gvcf（是否可以一步直接到vcf.gz/gvcf.gz），验证流程是否能跑通
- [ ] 添加压缩过程中的错误恢复、完善日志记录系统
- [ ] 添加进度条显示、提供压缩统计报告
### phase 2: 压缩算法与文件架构
- [ ] 想想怎么定义文件压缩后的gsc格式文件码流，组织结构等
- [ ] 边界怎么优雅地处理？
- [ ] 能正常输入输出后，针对已有的数据处理方法（已经写好了相应的压缩算法代码），压缩各个字段（按行列分块）
### phase 3: 性能指标收集 与 格式转换（plink和之前华大讨论想要的格式，这个也有性能指标）
- [ ] 压缩率对比、压缩和解压速度测试、内存使用量监控（压缩和解压）、格式转换的指标
- [ ] 检索速率、检索来增加随机访问 

---

# claude优化后的基因组压缩开发计划

## Phase 1: 核心I/O与基础验证框架

### 1.1 最小可行产品(MVP)搭建
- [ ] **VCF/GVCF解析器**
  - 实现流式解析，避免大文件内存溢出
  - 支持.gz输入的并行解压+解析
  - 按字段分离存储：CHROM, POS, REF, ALT, QUAL, INFO, FORMAT, 样本数据
  
- [ ] **中间态数据结构设计**
  ```
  中间态建议结构：
  - Header部分：原始header信息
  - 字段索引：各字段在压缩块中的位置
  - 数据块：按字段分组的压缩数据
  ```

- [ ] **基础压缩/解压流程**
  - 中间态 → Brotli压缩 → .gsc文件
  - .gsc文件 → Brotli解压 → 中间态 → VCF/GVCF重建
  - **关键**：先实现直接输出VCF，.gz输出可以后续优化

### 1.2 验证与错误处理
- [ ] **数据完整性验证**
  - 分块hash校验（每个字段单独校验）
  - 行数、列数一致性检查
  - 变体位置顺序验证
  
- [ ] **错误恢复机制**
  - 解析错误时的行级跳过
  - 压缩中断的断点续传
  - 损坏数据的部分恢复

### 1.3 用户体验基础
- [ ] **进度监控**
  - 基于文件大小的进度估算
  - 处理速度实时显示
  - 预计完成时间
  
- [ ] **日志系统**
  - 分级日志（INFO/WARN/ERROR）
  - 压缩统计自动记录
  - 性能指标收集埋点

## Phase 2: 智能压缩策略与文件格式

### 2.1 字段级压缩优化
- [ ] **位置信息优化**
  - CHROM: 字典编码
  - POS: 差值编码 + 变长整数
  
- [ ] **变体数据优化**
  - REF/ALT: 序列字典 + 引用编码
  - QUAL: 量化压缩（可选精度损失）
  
- [ ] **样本数据优化**
  - 基因型: 高频模式字典编码
  - FORMAT字段: 按类型分别优化

### 2.2 分块策略设计
```
建议的分块边界处理：
1. 按染色体自然分块
2. 大染色体按固定变体数分块（如10万个变体）
3. 块边界保存上下文信息以支持独立解压
```

- [ ] **分块压缩实现**
  - 支持并行压缩多个块
  - 块级索引构建
  - 块间依赖最小化

### 2.3 GSC格式规范设计
```
GSC文件结构建议：
Header (固定大小)
├── 魔数标识 (4 bytes)
├── 版本号 (2 bytes) 
├── 块数量 (4 bytes)
├── 索引偏移 (8 bytes)
└── 保留字段 (16 bytes)

索引区
├── 块1偏移+大小+hash
├── 块2偏移+大小+hash
└── ...

数据区
├── 原始Header压缩块
├── 字段1压缩块
├── 字段2压缩块
└── ...
```

## Phase 3: 性能评估与格式扩展

### 3.1 基准测试框架
- [ ] **测试数据集准备**
  - 小文件(< 100MB): 快速迭代测试
  - 中等文件(1-10GB): 性能基准
  - 大文件(>10GB): 扩展性测试
  
- [ ] **对比测试**
  ```
  测试维度：
  - 压缩率: 原始/gzip/brotli/gsc
  - 速度: 压缩/解压时间
  - 内存: 峰值内存占用
  - 准确性: 数据一致性验证
  ```

### 3.2 随机访问支持
- [ ] **索引构建**
  - 变体位置到块的映射
  - 样本到列的快速定位
  - 区域查询优化索引
  
- [ ] **部分解压**
  - 按染色体区域解压
  - 按样本子集解压
  - 块级缓存机制

### 3.3 格式转换支持
- [ ] **PLINK格式转换**
  - BED/BIM/FAM文件生成
  - 转换过程的性能优化
  
- [ ] **华大格式适配**
  - 具体格式需求确认
  - 转换精度与性能平衡

## 开发建议

### 优先级策略
1. **先完成Phase 1的MVP**，确保基本流程跑通
2. **小数据集验证**：用小文件（<10MB）快速迭代
3. **逐步扩大测试规模**，发现性能瓶颈
4. **并行开发**：I/O处理稳定后，可以并行优化压缩算法

### 技术要点
- **内存管理**：大文件处理时使用流式处理，避免全量加载
- **并行处理**：充分利用多核CPU，特别是解压和字段分离阶段  
- **缓存策略**：频繁访问的字典和索引数据使用内存缓存
- **错误边界**：每个处理阶段都要有清晰的错误边界和恢复策略

### 测试驱动建议
- 每个Phase都先写测试用例
- 建立自动化的回归测试
- 性能指标要有基线对比
- 数据完整性验证要覆盖边界情况